---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Fondamentaux pour l'utilisation de R {#sec-fondamentaux}

Il existe de plusieurs ressources en français pour apprendre à utiliser R. Nous vous recommandons en particulier :

-   [Introduction à R et au Tidyverse](https://juba.github.io/tidyverse/index.html) [@barnier2022]
-   [utilitR: documentation collaborative sur R de l'INSEE](https://www.book.utilitr.org/index.html) [@utilitr:2022]

Les bonnes ressources anglophones gratuites sont très nombreuses, très facile à trouver sur le Web. Les grands classiques est R for data science, de Grolemund et Wickham [-@grolemund2022]. On se focalise ici avec deux autres qui sont le plus en lien avec nos sujets :

-   [Geocomputation with R, a book on geographic data analysis, visualization and modeling](https://geocompr.robinlovelace.net/) [@lovelace2022].
-   [Mapme.biodiversity: Efficient Monitoring of Global Biodiversity Portfolios](https://mapme-initiative.github.io/mapme.biodiversity/index.html) [@görgen2022]

N'hésitez pas à chercher directement sur le Web en cas de problème. Vous serez souvent conduits vers les forums stackoverflow ou RStudio, qui sont aussi des ressources très précieuses pour résoudre des problèmes très spécifiques.

## Installation

On installe R et RStudio :

-   Télécharger et installer R ([page officielle proposant les installateurs et instructions d'installation](https://cloud.r-project.org/))
-   Télécharger et installer RStudio ([page officielle proposant les installateurs et instructions d'installation](https://www.rstudio.com/products/rstudio/download/#download))

> A noter : un nombre croissant d'utilisteurs utilise VS Code. C'est une alternative intéressante, pour des utilisateurs déjà confirmés :


## Librairies R

Plusieurs packages R sont utilisées pour ce projet. Les packages dans R sont des extensions de logiciels qui ajoutent des fonctionnalités spécifiques au langage R de base. Ils sont conçus pour faciliter l'analyse de données, la visualisation, la modélisation statistique, et bien plus encore. Les packages sont comme des boîtes à outils virtuelles qui permettent aux utilisateurs d'effectuer des tâches analytiques avancées sans avoir à réinventer la roue à chaque fois. Ils permettent de gagner du temps et de se concentrer sur la résolution de problèmes spécifiques à son domaine d'étude, au lieu de vous soucier de la programmation de fonctions de base.

Lors de la rédaction de publications scientifiques, il est important de citer correctement les packages R utilisés dans votre analyse. Assurez-vous d'inclure le nom complet du package ainsi que le nom de son auteur ou des auteurs. Zotero et RStudio permettent aisément d'inclure ces citations dans votre analyse.


### Mapme.biodiversity

On s'appuie sur le package R {mapme.biodiversity}, développé par la KfW dans le cadre de l'initiative commune MAPME qui associe la KfW et l'AFD. Le package {mapme.biodiversity} facilite l'acquisition et la préparation d'un grand nombre de données (CHIRPS, Global Forest Watch, FIRMS, SRTM, Worldpop...) et calculer un grand nombre d'indicateurs de manière harmonisée (active_fire_counts, biome classification, land cover classification, population count, precipitation, soil properties, tree cover loss, travel time...). Une documentation riche est disponible sur le portail dédié du package en question [@kluve_kfw_2022].

On mobilise aussi les codes d'analyse d'impact développés par la même équipe et mises à disposition dans le dépôt Github: <https://github.com/openkfw/mapme.protectedareas>. Le code développé par l'équipe est assez complexe. A des fins pédagogiques et pour s'assurer qu'on l'a bien compris, on propose ici une version simplifiée (en cours de développement).

### Autres packages

Les autres packages mobilisés dans pour ce cours sont listés dans le bloc de code ci-dessous : 

```{r}
library("tidyverse") # Une série de packages pour faciliter la manipulation de données
library("readxl") # Pour lire les fichiers excel (Carvalho et al. 2018)
library("writexl") # Pour écrire des fichiers excel
library("cowplot") # Pour arranger des graphiques en illustrations composées
library("gt") # Pour des rendus graphiques harmonisés html et pdf/LaTeX
library("sf") # Pour faciliter la manipulation de données géographiques
library("wdpar") # Pour télécharger simplement la base d'aires protégées WDPA
library("webdriver") # requis pour installer phantomjs pour wdpar
library("tmap") # Pour produire de jolies carte
library("geodata") # Pour télécharger simplement les frontières administratives
library("tidygeocoder") # pour obtenir les coordo GPS d'un point à partir de son nom
library("maptiles") # Pour télécharger des fonds de carte 
library("mapme.biodiversity") # Acquisition et traitement des données du projet
library("plm") # Linear Models for Panel Data and robust covariance matrices
library("broom") # pour reformater simplement les rendus de tests statistiques
library("stargazer") # Reformater de manière plus lisible les résumé des régressions
library("MatchIt") # Pour le matching
library("glm") # Modèles linéaires généralisés (pour le PSM)
library("optmatch") # Fonctions d'optimisation du matching
library("did") # Méthode de double différence échelonnée de Callaway et Sant'Anna
library("mapme.biodiversity")
library("cobalt") # Tables et graphs d'équilibre des groupes de matching

```



### Notebook Quarto

Les éléments ci-dessous constituent le support pour les sessions pratiques de cet atelier. Ils sont réalisés en suivant une approche ouverte et reproductible fondée sur un document de type "notebook" [@bedecarrats_alternative_2017]. Un notebook rassemble à la fois :

-   les lignes de code du programme statistique qui traite les données ;

-   les résultats (calculs, tableaux, graphiques...) produits lors de l'exécution de ce programme ;

-   le texte rédigé par les auteurs pour expliquer le processus d'analyse et en interpréter les résultats.

L'intérêt du format notebook, par rapport à l'utilisation de documents distincts pour traiter les données d'une part, et en analyser les résultats d'autre part, est multiple :

-   favoriser la reproductibité de la recherche (tout le processus de traitement, analyse, interprétation peut être inspecté et dupliqué) ;

-   faciliter le travail du chercheur (une interface pour tout faire) ; et

-   assurer les meilleures pratiques de collaboration (utilisation pour le versionnage, partage et fusion des travaux les outils performants développés en programmation informatique).

Les traitements sont réalisés en R, qui est à la fois un logiciel et un langage open sources dédiés à l'analyse de données. Les traitements R sont inclus dans un document Quarto, un format qui exécute aussi bien des codes en R, Python, e rendus dans différents formats (LaTeX/PDF, HTML ou Word).

La mise en forme des rendus Quarto est paramétrable. Ici, on a notamment placé un argument `code-fold: true` dans le fichier `_quarto.yml`. Cela fait que les blocs de code ne sont pas visible dans le rendu web par défaut : il faut cliquer sur "code" pour les déplier.



## Import des données

En très bref :

-   Pour les fichiers excle ou csv, dans le volet "files" du panneau en bas à droite de l'interface Rstudio, cliquer sur le fichier en question et utiliser l'assistant d'import.
-   Pour les autres fichiers, se référer à l'aide ou chercher sur internet.

Voir [cette page](https://juba.github.io) pour un topo sur les imports. \[#TODO:Préciser l'url\]

## Principes élémentaires de manipulation de données en R

On se focalise ici sur quelques aspects qui peuvent être requis pour la manipulation du code et à la marge. Points à traiter :

-   Le signe `<-` correspond à l'assignation d'une valeur à une variable. Il est presque équivalent à `=`, avec quelques différences dans certaines circonstances particulières, qui fait qu'on privilégie toujours `<-`.

```{r}
#| code-fold: false

# Ce qui suit un dièze n'est pas exécuté. On appelle ça un commentaire.

# On commence par faire une opération simple
3 + 4

# Ce qui équivaut à :
a <- 3
b <- 4
a + b

# Et on peut également stocker le résultat dans une nouvelle variable 
c <- a + b
c
```

-   R est constitué de fonctions. De nombreuses fonctions prédéfinies sont contenues dans la base de R ou dans des packages qu'on ajoute (qu'on verra plus tard).  La meilleure manière de comprendre ce qu'est une fonction est d'en créer une soi même. 

```{r}
#| code-fold: false
# On crée une fonction "ajoute" qui prend deux paramètres. 
# x est Un premier et y est celui qu'on ajoute
ajoute <- function(x, y) {
  x + y
}

# On peut maintenant utiliser cette foncction
ajoute(3, 4)

# On peut effectuer les mêmes opérations. Les valeurs a et b sont encore 
# en mémoire, donc on peut faire :
ajoute(a, b)

c <- ajoute(a, b)
c
ajoute(c, a)
```

Les fonctions disposent d'une documentation qu'on peut explorer en utilisant l'aide.

> Exercice pratique sur la recherche d 'aide.

- Le signe `%>%` est un "tuyau". On peut le lire à haute voix comme "ensuite". Par exemple :

```{r}
#| code-fold: false
library(tidyverse)

d <- a %>%
  ajoute(b) %>%
  ajoute(c)

d
```


-   na.rm : Les valeurs manquantes, notées NA dans R (certaines peuvent avoir pour valeur NaN). On utilise na.rm pour les éluder dans les opérations simples.


```{r}
#| code-fold: false
# On commence par créer les variables (les colonnes du tableau)
noms <- c("John", "Jack", "Cindy", "Samantha")
sexe <- c("homme", "homme", "femme", "femme")
ages <- c(42, 57, 24, NA)
poids <- c(87, 73, NA, NA)
tailles <- c(174, 198, 192, 164)

# On les rassemble dans un tableau 
ma_table <- data.frame(noms, sexe, ages, poids, tailles)

# On peut faire une moyenne sur les tailles car on a toutes les variables
mean(ma_table$tailles)
sum(ma_table$tailles)
# Mais la moyenne ne fonctionne pas immédiatement sur les poids ou les âges
# car il manque des variables
mean(ma_table$ages)
sum(ma_table$poids)

# Il faut préciser qu'il faut omettre les variables manquantes
mean(ma_table$ages, na.rm = TRUE)
sum(ma_table$poids, na.rm = TRUE)

```


-   verbes :

    - select : choisir des colonnes 
    - filter : choisir des lignes
    - mutate : modifier des valeurs
    - group_by : variables pour des tris 
    - créer des filtres : summarise

```{r}
#| code-fold: false
# Un exemple qui combine ces opérations
ma_table %>%
  filter(!is.na(ages)) %>%
  select(sexe, ages, tailles, poids) %>%
  group_by(sexe) %>%
  summarise(nb_pers = n(),
            somme_poids = sum(poids, na.rm = TRUE),
            taille_max = max(tailles, na.rm = TRUE),
            age_moy = mean(ages, na.rm = TRUE))
  
```


Deux opérations particulière requièrent une étude plus approfondies

-   Jointures : fusionner deux tableaux par une variable d'identification ("clé")
-   Pivots : passer un tableau de long en large
-   map : appliquer des opérations successives
-   unnest : déplier des listes imbriquées

Un point important est relatif aux types des variables : numérique, catégorielles, textes, dates, spatiales... En général, les opérations ne peuvent concerner que des variables du même type. Les fonctions sont souvent contraignantes quant aux types des variables qu'elles prennent comme arguments.

Pour une analyse plus approfondie, voir juba.

## Produire des cartes simples avec R

```{r}
#| code-fold: false
# Les librairies requises 
library(sf) # pour traiter des données spatiales
library(tmap) # pour faire des cartes

# Charger une carte des 
carte <- st_read("data/Vahatra/Vahatra98AP.shp") %>%
  st_make_valid()

# On projette la carte
tm_shape(carte) +
  tm_polygons(col = "cat__iucn") +
  tmap_options(check.and.fix = TRUE) + # Parce qu'on a quelques erreurs topo
  tm_layout(legend.outside = TRUE)

```


## Produire des graphiques avec R

On utilise le package ggplot, avec la syntaxe suivante.

```{r}
# On réalise un graphique simple
carte %>%
  ggplot(aes(x = cat__iucn, y = hectares)) +
  geom_col()

```

---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Fondamentaux pour l'utilisation de R {#sec-fondamentaux}

Il existe de plusieurs ressources en français pour apprendre à utiliser R. Nous vous recommandons en particulier :

-   [Introduction à R et au Tidyverse](https://juba.github.io/tidyverse/index.html) [@barnier2022]
-   [utilitR: documentation collaborative sur R de l'INSEE](https://www.book.utilitr.org/index.html) [@utilitr:2022]

Les bonnes ressources anglophones gratuites sont très nombreuses, très facile à trouver sur le Web. Les grands classiques est R for data science, de Grolemund et Wickham [-@grolemund2022]. On se focalise ici avec deux autres qui sont le plus en lien avec nos sujets :

-   [Geocomputation with R, a book on geographic data analysis, visualization and modeling](https://geocompr.robinlovelace.net/) [@lovelace2022].
-   [Mapme.biodiversity: Efficient Monitoring of Global Biodiversity Portfolios](https://mapme-initiative.github.io/mapme.biodiversity/index.html) [@görgen2022]

N'hésitez pas à chercher directement sur le Web en cas de problème. Vous serez souvent conduits vers les forums stackoverflow ou RStudio, qui sont aussi des ressources très précieuses pour résoudre des problèmes très spécifiques.

## Installation

On installe R et RStudio :

-   Télécharger et installer R ([page officielle proposant les installateurs et instructions d'installation](https://cloud.r-project.org/))
-   Télécharger et installer RStudio ([page officielle proposant les installateurs et instructions d'installation](https://www.rstudio.com/products/rstudio/download/#download))

> A noter : un nombre croissant d'utilisteurs utilise VS Code. C'est une alternative intéressante, pour des utilisateurs déjà confirmés :


## Librairies R

Plusieurs packages R sont utilisées pour ce projet. Les packages dans R sont des extensions de logiciels qui ajoutent des fonctionnalités spécifiques au langage R de base. Ils sont conçus pour faciliter l'analyse de données, la visualisation, la modélisation statistique, et bien plus encore. Les packages sont comme des boîtes à outils virtuelles qui permettent aux utilisateurs d'effectuer des tâches analytiques avancées sans avoir à réinventer la roue à chaque fois. Ils permettent de gagner du temps et de se concentrer sur la résolution de problèmes spécifiques à son domaine d'étude, au lieu de vous soucier de la programmation de fonctions de base.

Lors de la rédaction de publications scientifiques, il est important de citer correctement les packages R utilisés dans votre analyse. Assurez-vous d'inclure le nom complet du package ainsi que le nom de son auteur ou des auteurs. Zotero et RStudio permettent aisément d'inclure ces citations dans votre analyse.


### Mapme.biodiversity

On s'appuie sur le package R {mapme.biodiversity}, développé par la KfW dans le cadre de l'initiative commune MAPME qui associe la KfW et l'AFD. Le package {mapme.biodiversity} facilite l'acquisition et la préparation d'un grand nombre de données (CHIRPS, Global Forest Watch, FIRMS, SRTM, Worldpop...) et calculer un grand nombre d'indicateurs de manière harmonisée (active_fire_counts, biome classification, land cover classification, population count, precipitation, soil properties, tree cover loss, travel time...). Une documentation riche est disponible sur le portail dédié du package en question [@kluve_kfw_2022].

On mobilise aussi les codes d'analyse d'impact développés par la même équipe et mises à disposition dans le dépôt Github: <https://github.com/openkfw/mapme.protectedareas>. Le code développé par l'équipe est assez complexe. A des fins pédagogiques et pour s'assurer qu'on l'a bien compris, on propose ici une version simplifiée (en cours de développement).

### Autres packages

Les autres packages mobilisés dans pour ce cours sont listés dans le bloc de code ci-dessous : 

```{r}
library("tidyverse") # Une série de packages pour faciliter la manipulation de données
library("readxl") # Pour lire les fichiers excel (Carvalho et al. 2018)
library("writexl") # Pour écrire des fichiers excel
library("cowplot") # Pour arranger des graphiques en illustrations composées
library("gt") # Pour des rendus graphiques harmonisés html et pdf/LaTeX
library("sf") # Pour faciliter la manipulation de données géographiques
library("wdpar") # Pour télécharger simplement la base d'aires protégées WDPA
library("webdriver") # requis pour installer phantomjs pour wdpar
library("tmap") # Pour produire de jolies carte
library("geodata") # Pour télécharger simplement les frontières administratives
library("tidygeocoder") # pour obtenir les coordo GPS d'un point à partir de son nom
library("maptiles") # Pour télécharger des fonds de carte 
library("mapme.biodiversity") # Acquisition et traitement des données du projet
library("plm") # Linear Models for Panel Data and robust covariance matrices
library("broom") # pour reformater simplement les rendus de tests statistiques
library("stargazer") # Reformater de manière plus lisible les résumé des régressions
library("MatchIt") # Pour le matching
library("glm") # Modèles linéaires généralisés (pour le PSM)
library("optmatch") # Fonctions d'optimisation du matching
library("did") # Méthode de double différence échelonnée de Callaway et Sant'Anna
library("mapme.biodiversity")
library("cobalt") # Tables et graphs d'équilibre des groupes de matching

```



### Notebook Quarto

Les éléments ci-dessous constituent le support pour les sessions pratiques de cet atelier. Ils sont réalisés en suivant une approche ouverte et reproductible fondée sur un document de type "notebook" [@bedecarrats_alternative_2017]. Un notebook rassemble à la fois :

-   les lignes de code du programme statistique qui traite les données ;

-   les résultats (calculs, tableaux, graphiques...) produits lors de l'exécution de ce programme ;

-   le texte rédigé par les auteurs pour expliquer le processus d'analyse et en interpréter les résultats.

L'intérêt du format notebook, par rapport à l'utilisation de documents distincts pour traiter les données d'une part, et en analyser les résultats d'autre part, est multiple :

-   favoriser la reproductibité de la recherche (tout le processus de traitement, analyse, interprétation peut être inspecté et dupliqué) ;

-   faciliter le travail du chercheur (une interface pour tout faire) ; et

-   assurer les meilleures pratiques de collaboration (utilisation pour le versionnage, partage et fusion des travaux les outils performants développés en programmation informatique).

Les traitements sont réalisés en R, qui est à la fois un logiciel et un langage open sources dédiés à l'analyse de données. Les traitements R sont inclus dans un document Quarto, un format qui exécute aussi bien des codes en R, Python, e rendus dans différents formats (LaTeX/PDF, HTML ou Word).

La mise en forme des rendus Quarto est paramétrable. Ici, on a notamment placé un argument `code-fold: true` dans le fichier `_quarto.yml`. Cela fait que les blocs de code ne sont pas visible dans le rendu web par défaut : il faut cliquer sur "code" pour les déplier.


## Import des données

En très bref :

-   Pour les fichiers excel ou csv, dans le volet "files" du panneau en bas à droite de l'interface Rstudio, cliquer sur le fichier en question et utiliser l'assistant d'import.


- Pour certaines, il existe des packages ad hoc. Par exemple WDPA ou GADM.

-   Pour les autres formats de fichiers, se référer à l'aide ou chercher sur internet.

Voir [cette page](https://juba.github.io) pour un topo sur les imports. \[#TODO:Préciser l'url\]

## Principes élémentaires de manipulation de données en R

On se focalise ici sur quelques aspects qui peuvent être requis pour la manipulation du code et à la marge. Points à traiter :

-   Le signe `<-` correspond à l'assignation d'une valeur à une variable. Il est presque équivalent à `=`, avec quelques différences dans certaines circonstances particulières, qui fait qu'on privilégie toujours `<-`.

```{r}
#| code-fold: false

# Ce qui suit un dièze n'est pas exécuté. On appelle ça un commentaire.

# On commence par faire une opération simple
3 + 4

# Ce qui équivaut à :
a <- 3
b <- 4
a + b

# Et on peut également stocker le résultat dans une nouvelle variable 
c <- a + b
c
```

-   R est constitué de fonctions. De nombreuses fonctions prédéfinies sont contenues dans la base de R ou dans des packages qu'on ajoute (qu'on verra plus tard).  La meilleure manière de comprendre ce qu'est une fonction est d'en créer une soi même. 

```{r}
#| code-fold: false
# On crée une fonction "ajoute" qui prend deux paramètres. 
# x est Un premier et y est celui qu'on ajoute
ajoute <- function(x, y) {
  x + y
}

# On peut maintenant utiliser cette foncction
ajoute(3, 4)

# On peut effectuer les mêmes opérations. Les valeurs a et b sont encore 
# en mémoire, donc on peut faire :
ajoute(a, b)

c <- ajoute(a, b)
c
ajoute(c, a)
```

Les fonctions disposent d'une documentation qu'on peut explorer en utilisant l'aide.

> Exercice pratique sur la recherche d 'aide.

- Le signe `%>%` est un "tuyau". On peut le lire à haute voix comme "ensuite". Par exemple :

```{r}
#| code-fold: false
library(tidyverse)

d <- a %>%
  ajoute(b) %>%
  ajoute(c)

d
```


-   na.rm : Les valeurs manquantes, notées NA dans R (certaines peuvent avoir pour valeur NaN). On utilise na.rm pour les éluder dans les opérations simples.


```{r}
#| code-fold: false
# On commence par créer les variables (les colonnes du tableau)
noms <- c("John", "Jack", "Cindy", "Samantha")
sexe <- c("homme", "homme", "femme", "femme")
ages <- c(42, 57, 24, NA)
poids <- c(87, 73, NA, NA)
tailles <- c(174, 198, 192, 164)

# On les rassemble dans un tableau 
ma_table <- data.frame(noms, sexe, ages, poids, tailles)

# On peut faire une moyenne sur les tailles car on a toutes les variables
mean(ma_table$tailles)
sum(ma_table$tailles)
# Mais la moyenne ne fonctionne pas immédiatement sur les poids ou les âges
# car il manque des variables
mean(ma_table$ages)
sum(ma_table$poids)

# Il faut préciser qu'il faut omettre les variables manquantes
mean(ma_table$ages, na.rm = TRUE)
sum(ma_table$poids, na.rm = TRUE)

```


-   verbes :

    - select : choisir des colonnes 
    - filter : choisir des lignes
    - mutate : modifier des valeurs
    - group_by : variables pour des tris 
    - créer des filtres : summarise

```{r}
#| code-fold: false
# Un exemple qui combine ces opérations
ma_table %>%
  filter(!is.na(ages)) %>%
  select(sexe, ages, tailles, poids) %>%
  group_by(sexe) %>%
  summarise(nb_pers = n(),
            somme_poids = sum(poids, na.rm = TRUE),
            taille_max = max(tailles, na.rm = TRUE),
            age_moy = mean(ages, na.rm = TRUE))
  
```


Deux opérations particulière requièrent une étude plus approfondies

-   Jointures : fusionner deux tableaux par une variable d'identification ("clé")
-   Pivots : passer un tableau de long en large
-   map : appliquer des opérations successives
-   unnest : déplier des listes imbriquées

Un point important est relatif aux types des variables : numérique, catégorielles, textes, dates, spatiales... En général, les opérations ne peuvent concerner que des variables du même type. Les fonctions sont souvent contraignantes quant aux types des variables qu'elles prennent comme arguments.

Pour une analyse plus approfondie, voir juba.

## Produire des cartes simples avec R

```{r}
#| code-fold: false
# Les librairies requises 
library(sf) # pour traiter des données spatiales
library(tmap) # pour faire des cartes

# Charger une carte des 
carte <- st_read("data/Vahatra/Vahatra98AP.shp") %>%
  st_make_valid()

# On projette la carte
tm_shape(carte) +
  tm_polygons(col = "cat__iucn") +
  tmap_options(check.and.fix = TRUE) + # Parce qu'on a quelques erreurs topo
  tm_layout(legend.outside = TRUE)

```


## Produire des graphiques avec R

On utilise le package ggplot, avec la syntaxe suivante.

```{r}
# On réalise un graphique simple
carte %>%
  ggplot(aes(x = cat__iucn, y = hectares)) +
  geom_col()

```



